{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write start : start\n",
      "Enter your name : vicky\n",
      "1). Mobile \n",
      "2). Laptop \n",
      "\n",
      "Which Camera wanna use : 1\n",
      "Selfie Time\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "ID Time\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n",
      "Model trained sucessefully\n",
      "(39, 92.77756650087836)\n",
      "(39, 99.6771938682598)\n",
      "(148, 104.13461539390725)\n",
      "(147, 95.20612091885985)\n",
      "(86, 101.49270973547308)\n",
      "(86, 103.33592764979082)\n",
      "(39, 90.27751914029855)\n",
      "(144, 94.3045510823777)\n",
      "(148, 111.58931999346497)\n",
      "(147, 90.80268617068006)\n",
      "(147, 93.10894848308963)\n",
      "(4, 69.15607967679556)\n",
      "(3, 73.91295240372025)\n",
      "(86, 94.94947754935153)\n",
      "(68, 68.0424595056579)\n",
      "(167, 51.88674095248267)\n",
      "Write end : end\n",
      "1. Face matched...\n",
      "Next Customer ? (1/0) : 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input('Write start : ')\n",
    "\n",
    "# def initialise():\n",
    "\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "import pyttsx3\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "speaker = pyttsx3.init()\n",
    "speaker.say(\"Testing Speaker...\")\n",
    "speaker.runAndWait()\n",
    "\n",
    "yourname = 'NULL'\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('C:/Users/Vicky Kumar/Desktop/face detection attendence file/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# =========================================================================================================\n",
    "\n",
    "\n",
    "# def takephoto():\n",
    "\n",
    "speaker.say(\"Enter your name\")\n",
    "speaker.runAndWait()\n",
    "yourname = input('Enter your name : ')\n",
    "\n",
    "speaker.say(\"Hello, \" + str(yourname))\n",
    "speaker.runAndWait()\n",
    "\n",
    "speaker.say('     Get ready and Please Smile, It\\'s Selfie Time...')\n",
    "speaker.runAndWait()\n",
    "\n",
    "# import os mkdir str(yourname)\n",
    "# os.mkdir(datasets + str(yourname) + '/')\n",
    "\n",
    "datasets = 'C:/Users/Vicky Kumar/Desktop/face detection attendence file/model/'\n",
    "# path = os.path.join(datasets, yourname) \n",
    "# if not os.path.isdir(path): \n",
    "#     os.mkdir(path) \n",
    "\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "\n",
    "#   gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    if faces is ():\n",
    "        return None\n",
    "\n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "def photo(ip, count, totalphoto):\n",
    "\n",
    "    # Initialize Webcam of given ip\n",
    "    cap = cv2.VideoCapture(ip)\n",
    "        \n",
    "    # Collect 100 samples of your face from webcam input\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if face_extractor(frame) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Save file in specified directory with unique name\n",
    "            file_name_path = 'C:/Users/Vicky Kumar/Desktop/face detection attendence file/model/'+ str(count) + '.jpg'\n",
    "#              + str(yourname) + '/' \n",
    "            cv2.imwrite(file_name_path, face)\n",
    "\n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Cropper', face)\n",
    "\n",
    "        else:\n",
    "            print(\"Face not found\")\n",
    "            pass\n",
    "\n",
    "        if cv2.waitKey(1) == 13 or count == totalphoto: #13 is the Enter Key\n",
    "            break\n",
    "            \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "            \n",
    "print('1). Mobile \\n2). Laptop \\n')\n",
    "speaker.say(\"Enter your Choice : \")\n",
    "speaker.runAndWait()\n",
    "\n",
    "camera = input('Which Camera wanna use : ')\n",
    "\n",
    "if camera == '1':\n",
    "    url = 'http://10.0.251.141:8080/video'\n",
    "else:\n",
    "    url = 0\n",
    "\n",
    "print('Selfie Time')\n",
    "for _ in range(5):\n",
    "    speaker.say(\"Selfie Time\")\n",
    "    speaker.runAndWait()\n",
    "photo(url,0,100)\n",
    "\n",
    "print('ID Time')\n",
    "for _ in range(5):\n",
    "    speaker.say(\"ID Time\")\n",
    "    speaker.runAndWait()\n",
    "    \n",
    "photo('http://10.0.251.141:8080/video',100,200)\n",
    "# photo(url,100,200)\n",
    "\n",
    "\n",
    "# =============================================================================================================\n",
    "\n",
    "\n",
    "# print(cv2.__version__)\n",
    "\n",
    "# os.chdir(r'C:\\Users\\Vicky Kumar\\Desktop\\face detection attendence file\\model')\n",
    "\n",
    "# for i in range(3):\n",
    "#     print(os.listdir()[i])\n",
    "\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = 'C:/Users/Vicky Kumar/Desktop/face detection attendence file/model/'\n",
    "# + str(yourname) + '/'\n",
    "\n",
    "# a=listdir('d:/faces')\n",
    "# print(a)\n",
    "# \"\"\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.array(Labels, dtype=np.int32)\n",
    "image=sys.argv[1]\n",
    "img = cv2.imread(image)\n",
    "face = face_classifier.detectMultiScale(img, 1.1, 4)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face_LBPHFaceRecognizer.create()\n",
    "# model=cv2.f\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n",
    "\n",
    "\n",
    "\n",
    "# ===========================================================================================\n",
    "\n",
    "url = 'http://10.0.251.141:8080/video'\n",
    "# url = 0\n",
    "\n",
    "# def recog():\n",
    "    \n",
    "def face_detector(img, size=0.5):\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "again = '1'\n",
    "while again == '1':\n",
    "    # Open Webcam\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    allowed = 0\n",
    "\n",
    "    while(cv2.waitKey(30) != ord('q')):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        image, face = face_detector(frame)\n",
    "\n",
    "        try:\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Pass face to prediction model\n",
    "            # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "            results = model.predict(face)\n",
    "            print(results)\n",
    "            if results[1] < 500:\n",
    "                confidence = int( 100 * (1 - (results[1])/400) )\n",
    "                display_string = str(confidence) + '% Confident it is User'\n",
    "\n",
    "            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "\n",
    "            if confidence > 85 :\n",
    "                allowed = 1\n",
    "                cv2.putText(image, \"Hey \" + str(yourname), (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                speaker.say(\"         hii, i know you, you are \" + str(yourname))\n",
    "                speaker.runAndWait()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                speaker.say(\"Locked\")\n",
    "                speaker.runAndWait()\n",
    "        except:\n",
    "            cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "    #         speaker.say(\"No face Found\")\n",
    "    #         speaker.runAndWait()\n",
    "            pass\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if allowed == 1:\n",
    "        print('{}. Face matched...'.format(allowed))\n",
    "    else:\n",
    "        print('{}. Face NOT matched...'.format(allowed))\n",
    "        \n",
    "    again = input('Next Customer ? (1/0) : ')\n",
    "    \n",
    "else:\n",
    "    speaker.say(\"Thanks for using this Software ...\")\n",
    "    speaker.runAndWait()\n",
    "    \n",
    "    \n",
    "# ==========================================================================================================\n",
    "            \n",
    "    \n",
    "# def main():\n",
    "\n",
    "#     initialise()\n",
    "#     takephoto()\n",
    "#     recog()\n",
    "# #     os.rmdir('C:/Users/Vicky Kumar/Desktop/face detection attendence file/model/' + str(yourname))\n",
    "    \n",
    "# if __name__== \"__main__\" :\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 113)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(30), ord('q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 43.845028844380764)\n",
      "1. Face matched...\n",
      "Next Customer ? (1/0) : 1\n",
      "(155, 96.06775569237307)\n",
      "(39, 99.18543998845287)\n",
      "(137, 101.78455032423935)\n",
      "(137, 100.19716080359669)\n",
      "(38, 93.3082256300822)\n",
      "(137, 96.93059604549497)\n",
      "(137, 90.59722060309839)\n",
      "(137, 77.10945465206154)\n",
      "(137, 73.15857249895136)\n",
      "(137, 81.72404797591537)\n",
      "(117, 76.27988054542318)\n",
      "(137, 76.5668778926793)\n",
      "(137, 74.45594834902067)\n",
      "(137, 79.04444365857296)\n",
      "(137, 75.94782357372718)\n",
      "(46, 77.50689184689553)\n",
      "(117, 72.64844270058445)\n",
      "(117, 74.2348460781149)\n",
      "(117, 70.58002168322444)\n",
      "(117, 72.14357193465835)\n",
      "(115, 71.5650933612703)\n",
      "(27, 80.77879929269471)\n",
      "(112, 74.12852880026735)\n",
      "(112, 77.59931549312)\n",
      "(117, 71.77052200397081)\n",
      "(137, 73.08390779285013)\n",
      "(137, 72.30999014684626)\n",
      "(124, 41.767180698679525)\n",
      "1. Face matched...\n",
      "Next Customer ? (1/0) : 0\n"
     ]
    }
   ],
   "source": [
    "# Repeat it...\n",
    "\n",
    "# ===========================================================================================\n",
    "\n",
    "url = 'http://10.0.251.141:8080/video'\n",
    "# url = 0\n",
    "\n",
    "# def recog():\n",
    "    \n",
    "def face_detector(img, size=0.5):\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "again = '1'\n",
    "while again == '1':\n",
    "    # Open Webcam\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    allowed = 0\n",
    "\n",
    "    while(cv2.waitKey(30) != ord('q')):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        image, face = face_detector(frame)\n",
    "\n",
    "        try:\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Pass face to prediction model\n",
    "            # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "            results = model.predict(face)\n",
    "            print(results)\n",
    "            if results[1] < 500:\n",
    "                confidence = int( 100 * (1 - (results[1])/400) )\n",
    "                display_string = str(confidence) + '% Confident it is User'\n",
    "\n",
    "            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "\n",
    "            if confidence > 85 :\n",
    "                allowed = 1\n",
    "                cv2.putText(image, \"Hey \" + str(yourname), (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                speaker.say(\"         hii, i know you, you are \" + str(yourname))\n",
    "                speaker.runAndWait()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                speaker.say(\"Locked\")\n",
    "                speaker.runAndWait()\n",
    "        except:\n",
    "            cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "    #         speaker.say(\"No face Found\")\n",
    "    #         speaker.runAndWait()\n",
    "            pass\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if allowed == 1:\n",
    "        print('{}. Face matched...'.format(allowed))\n",
    "    else:\n",
    "        print('{}. Face NOT matched...'.format(allowed))\n",
    "        \n",
    "    again = input('Next Customer ? (1/0) : ')\n",
    "    \n",
    "else:\n",
    "    speaker.say(\"Thanks for using this Software ...\")\n",
    "    speaker.runAndWait()    \n",
    "# ==========================================================================================================\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
